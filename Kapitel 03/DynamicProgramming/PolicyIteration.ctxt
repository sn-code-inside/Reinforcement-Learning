#BlueJ class context
comment0.target=PolicyIteration
comment0.text=\r\n\ An\ agent\ environment\ for\ computing\ optimal\ tactics\ in\ the\ hamster\ world\ using\ PolicyIteration.\r\n\ \r\n\ Supplementary\ material\ to\ the\ book\:\ \r\n\ "Reinforcement\ Learning\ From\ Scratch\:\ Understanding\ Current\ Approaches\ -\ with\ Examples\ in\ Java\ and\ Greenfoot"\ by\ Uwe\ Lorenz.\r\n\ https\://link.springer.com/book/10.1007/978-3-031-09030-1\r\n\ \r\n\ Ausgabe\ auf\ Deutsch\:\ https\://link.springer.com/book/9783662683101\r\n\ \r\n\ Licensing\ CC-BY-SA\ 4.0\ \r\n\ Attribution\ -\ Sharing\ under\ the\ same\ conditions\r\n\ \r\n\ www.facebook.com/ReinforcementLearningJava\r\n\ github.com/sn-code-inside/Reinforcement-Learning\r\n\r\n\ www.x-ai.eu\r\n\ \r\n\ @author\ Uwe\ Lorenz\r\n\ @version\ 1.2\ (14.11.2023)\r\n
comment1.params=
comment1.target=PolicyIteration()
comment1.text=\r\n\ Constructor\ for\ objects\ of\ class\ PolicyIteration.\r\n\ \r\n
comment10.params=
comment10.target=void\ clearV()
comment10.text=\r\n\ \ Resets\ all\ field\ valuations\ to\ 0.\r\n
comment11.params=
comment11.target=void\ updateDisplay()
comment11.text=\r\n\ Updates\ the\ display\ of\ the\ state\ value\ objects\ in\ the\ territory\ according\ to\ V(s).\r\n
comment12.params=x\ y
comment12.target=void\ updateValue(int,\ int)
comment12.text=\r\n\ Updates\ the\ display\ of\ the\ state\ value\ objects\ in\ the\ territory\ according\ to\ V(s).\r\n\ @param\ x\ X-component\ of\ the\ state\ (column).\r\n\ @param\ y\ Y-component\ of\ the\ state\ (row).\r\n
comment13.params=i\ j
comment13.target=void\ updatePolicymarker(int,\ int)
comment13.text=\r\n\ Updates\ the\ display\ of\ the\ policy\ objects\ in\ the\ territory\ according\ to\ pi(s).\r\n\ @param\ i\ X-component\ of\ the\ state\ (column).\r\n\ @param\ j\ Y-component\ of\ the\ state\ (row).\r\n
comment2.params=
comment2.target=void\ act()
comment3.params=n
comment3.target=void\ iterate(int)
comment3.text=\r\n\ Performs\ a\ ValueIteration\ completely\ up\ to\ the\ termination\ criterion.\r\n\ @param\ n\ maximum\ number\ of\ iterations\r\n
comment4.params=
comment4.target=boolean\ policyImprovement()
comment4.text=\r\n\ Updates\ the\ policy\ if\ a\ better\ action\ option\ is\ found\ with\ the\ given\ state\ values.\r\n
comment5.params=
comment5.target=boolean\ evaluateStates()
comment5.text=\r\n\ Performs\ a\ sweep\ over\ all\ states\ s\ of\ the\ state\ space\ S\ (makes\ a\ "sweep").\r\n
comment6.params=x\ y
comment6.target=Actionvalue\ targetOrientedEvaluation(int,\ int)
comment6.text=\r\n\ Calculates\ the\ value\ of\ a\ state\ from\ the\ best\ possible\ subsequent\ state\ distribution.\r\n\ @param\ x\ X-component\ of\ the\ state\ (column).\r\n\ @param\ y\ Y-component\ of\ the\ state\ (row).\r\n\ @return\ Actionvalue\r\n
comment7.params=subsequentStates
comment7.target=double\ weightedValuation(java.util.ArrayList)
comment7.text=\r\n\ Sum\ over\ P(s'|s,a)*V(s')\ ,for\ all\ s'\ from\ S\ (\ for\ which\ P(s')>0\ ),\ i.e.\ add\ up\ probability*valuation\ for\ each\ subsequent\ state.\r\n\ @param\ subsequentStates\ List\ of\ possible\ consequential\ states\ with\ their\ probabilities.\r\n\ @return\ weighted\ sum\ of\ the\ valuations\ of\ the\ possible\ subsequent\ states\ (of\ an\ action).\r\n
comment8.params=x\ y
comment8.target=Actionvalue\ policybasedEvaluation(int,\ int)
comment8.text=\r\n\ Calculates\ the\ expected\ reward\ based\ on\ a\ given\ policy.\r\n\ @param\ x\ X-component\ of\ the\ state\ (column).\r\n\ @param\ y\ Y-component\ of\ the\ state\ (row).\r\n\ @return\ Actionvalue\ according\ to\ given\ policy.\r\n
comment9.params=x\ y
comment9.target=double\ getV(int,\ int)
comment9.text=\r\n\ Returns\ the\ current\ state\ value.\r\n\ @param\ x\ X-component\ of\ the\ state\ (column).\r\n\ @param\ y\ Y-component\ of\ the\ state\ (row).\r\n\ @return\ the\ current\ state\ value.\r\n
numComments=14
