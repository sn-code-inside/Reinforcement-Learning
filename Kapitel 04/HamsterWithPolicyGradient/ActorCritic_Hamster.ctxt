#BlueJ class context
comment0.target=ActorCritic_Hamster
comment0.text=\r\n\ A\ hamster-agent\ with\ "actor-critic"-policy.\r\n\ \r\n\ Supplementary\ material\ to\ the\ book\:\ \r\n\ "Reinforcement\ Learning\ From\ Scratch\:\ Understanding\ Current\ Approaches\ -\ with\ Examples\ in\ Java\ and\ Greenfoot"\ by\ Uwe\ Lorenz.\r\n\ https\://link.springer.com/book/10.1007/978-3-031-09030-1\r\n\ \r\n\ Ausgabe\ auf\ Deutsch\:\ https\://link.springer.com/book/9783662683101\r\n\ \r\n\ Licensing\ CC-BY-SA\ 4.0\ \r\n\ Attribution\ -\ Sharing\ under\ the\ same\ conditions\r\n\ \r\n\ www.facebook.com/ReinforcementLearningJava\r\n\ github.com/sn-code-inside/Reinforcement-Learning\r\n\r\n\ www.x-ai.eu\r\n\ \r\n\ @author\ Uwe\ Lorenz\r\n\ @version\ 1.2\ (14.11.2023)\r\n
comment1.params=
comment1.target=ActorCritic_Hamster()
comment10.params=s_key\ theta
comment10.target=void\ setTheta(java.lang.String,\ double[])
comment10.text=\ \r\n\ Set\ action\ preferences\ for\ a\ given\ state.\r\n\ @param\ s_key\ state\ key\r\n\ @param\ theta\ parameters\ for\ action\ preferences\r\n
comment11.params=s_key
comment11.target=double[]\ getTheta(java.lang.String)
comment11.text=\ \r\n\ Get\ action\ preferences\ for\ a\ given\ state.\r\n\ @param\ s_key\ state\ key\r\n\ @return\ parameters\ for\ action\ preferences\r\n
comment12.params=s_key\ a
comment12.target=double\ getTheta_A(java.lang.String,\ int)
comment12.text=\ \r\n\ Get\ preferences\ for\ given\ state\ and\ action.\r\n\ @param\ s_key\ state\ key\r\n\ @param\ a\ action\r\n\ @return\ parameter\ describing\ the\ action\ preference.\r\n
comment13.params=s\ v
comment13.target=void\ setV(java.lang.String,\ double)
comment13.text=\r\n\ Sets\ a\ value\ for\ state\ s.\r\n\ @param\ s\ state\ key\r\n\ @param\ v\ Evaluation\ of\ the\ state\r\n
comment14.params=s
comment14.target=java.lang.Double\ getV(java.lang.String)
comment14.text=\r\n\ Gets\ value\ for\ state\ s.\r\n\ @param\ s\ state\ key\r\n\ @return\ value\ for\ state\ s.\r\n
comment2.params=world
comment2.target=void\ addedToWorld(greenfoot.World)
comment3.params=
comment3.target=void\ act()
comment4.params=
comment4.target=java.lang.String\ getState()
comment5.params=s\ a\ reward\ s_new\ episodeEnd
comment5.target=void\ update(java.lang.String,\ int,\ double,\ java.lang.String,\ boolean)
comment5.text=\r\n\ Actor-critic\ Update\r\n
comment6.params=s_key
comment6.target=double[]\ P_Policy(java.lang.String)
comment6.text=\r\n\ Stochastic\ policy\ of\ the\ agent.\ Assigns\ a\ probability\ distribution\ to\ a\ state\ over\ the\ set\ of\ possible\ actions.\r\n\ @param\ s_key\ state\ key\r\n\ @return\ probability\ distribution\ for\ actions\ a\ in\ [0,1,...,n-1].\r\n
comment7.params=n\ A_s\ s
comment7.target=double[]\ P_SoftMax(int,\ java.util.List,\ java.lang.String)
comment7.text=\r\n\ Assigns\ a\ probability\ distribution\ to\ a\ state\ over\ the\ set\ of\ possible\ actions\r\n\ according\ to\ softmax\ action\ selection\ strategy.\r\n\ @param\ n\ number\ of\ sucessor\ states\r\n\ @param\ A_s\ List\ of\ action\ options\ available\ to\ the\ agent\ at\ the\ given\ time\ in\ s.\r\n\ @param\ s_key\ key\ for\ given\ state\ s\r\n\ @return\ probability\ distribution\ for\ actions\ a\ in\ [0,1,...,n-1].\r\n
comment8.params=x\ y\ score
comment8.target=java.lang.String\ getStateKey(int,\ int,\ int)
comment8.text=\r\n\ Creates\ the\ key\ for\ accessing\ the\ table\ for\ V(s)\ an\ theta(s)\ .\ If\ it\ does\ not\ exist,\ the\ corresponding\ record\ is\ created.\r\n\ @param\ x\ column\ in\ the\ gridworld\r\n\ @param\ y\ row\ in\ the\ gridworld\r\n\ @param\ score\ collected\ grains\r\n\ @return\ state\ key\r\n
comment9.params=
comment9.target=void\ startNewEpisode()
comment9.text=\r\n\ A\ new\ episode\ is\ started,\ i.e.\ logging,\ counter\ updates\ or\ reset\ and\ set\ agent\ to\ start\ position.\r\n\ Perform\ an\ evaluation\ period\ if\ necessary.\r\n
numComments=15
