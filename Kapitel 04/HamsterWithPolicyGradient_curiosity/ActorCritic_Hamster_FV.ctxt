#BlueJ class context
comment0.target=ActorCritic_Hamster_FV
comment0.text=\r\n\ A\ hamster-agent\ in\ partially\ observable\ environment\ with\ "actor-critic"-policy.\r\n\ \r\n\ Supplementary\ material\ to\ the\ book\:\ \r\n\ "Reinforcement\ Learning\ From\ Scratch\:\ Understanding\ Current\ Approaches\ -\ with\ Examples\ in\ Java\ and\ Greenfoot"\ by\ Uwe\ Lorenz.\r\n\ https\://link.springer.com/book/10.1007/978-3-031-09030-1\r\n\ \r\n\ Ausgabe\ auf\ Deutsch\:\ https\://link.springer.com/book/9783662683101\r\n\ \r\n\ Licensing\ CC-BY-SA\ 4.0\ \r\n\ Attribution\ -\ Sharing\ under\ the\ same\ conditions\r\n\ \r\n\ www.facebook.com/ReinforcementLearningJava\r\n\ github.com/sn-code-inside/Reinforcement-Learning\r\n\r\n\ www.x-ai.eu\r\n\ \r\n\ @author\ Uwe\ Lorenz\r\n\ @version\ 1.2\ (14.11.2023)\r\n
comment1.params=
comment1.target=ActorCritic_Hamster_FV()
comment10.params=
comment10.target=void\ startNewEpisode()
comment10.text=\r\n\ A\ new\ episode\ is\ started,\ i.e.\ logging,\ counter\ updates\ or\ reset\ and\ set\ agent\ to\ start\ position.\r\n\ Perform\ an\ evaluation\ period\ if\ necessary.\r\n
comment11.params=xs\ a
comment11.target=double[]\ getFeatureVector(java.lang.String,\ int)
comment11.text=\r\n\ Creates\ the\ numerical\ feature\ vector\ for\ calculations\ from\ feature\ string\ and\ related\ action.\ \r\n\ @param\ xs\ the\ feature-state\ key\r\n\ @param\ a\ action\r\n\ @return\ numerical\ feature\ vector\r\n
comment12.params=xs
comment12.target=double[]\ getObservationVector(java.lang.String)
comment12.text=\r\n\ \ Creates\ the\ numerical\ feature\ vector\ for\ calculations\ from\ sensoric\ feature\ string.\r\n\ \ @param\ xs\ string\ with\ observed\ sensoric\ features\r\n\ \ @return\ numerical\ vector\r\n
comment13.params=
comment13.target=int\ getSizeOfObservationVector()
comment13.text=\r\n\ Calculates\ the\ size\ of\ the\ vector,\ that\ contains\ the\ features\ of\ the\ observation.\ \r\n\ @param\ size\ of\ the\ observation\ vector\r\n
comment14.params=
comment14.target=java.lang.String\ getState()
comment15.params=xs\ a\ theta
comment15.target=void\ setTheta(java.lang.String,\ int,\ double[])
comment15.text=\ \r\n\ Set\ parameters\ for\ given\ (feature-)state-action\ pair.\r\n\ @param\ xs\ state\ key\ (based\ on\ features)\r\n\ @param\ a\ action\r\n\ @param\ parameters\ theta\ for\ calculating\ action\ preferences\r\n
comment16.params=xs\ a
comment16.target=double[]\ getTheta(java.lang.String,\ int)
comment16.text=\ \r\n\ Get\ parameters\ for\ a\ given\ (feature-)state-action\ pair.\r\n\ @param\ xs\ state\ key\ (based\ on\ features)\r\n\ @param\ a\ action\r\n\ @return\ parameters\ for\ calculating\ action\ preferences\r\n
comment17.params=xs\ a
comment17.target=java.lang.String\ getStateActionKey(java.lang.String,\ int)
comment17.text=\r\n\ Creates\ the\ key\ for\ accessing\ the\ table\ theta(s,a)\ based\ on\ features\ and\ action.\ \r\n\ @param\ xs\ the\ feature-state\ key\r\n\ @param\ a\ action\r\n\ @return\ key\r\n
comment18.params=n\ A_s\ s
comment18.target=double[]\ P_SoftMax(int,\ java.util.List,\ java.lang.String)
comment18.text=\r\n\ Assigns\ a\ probability\ distribution\ to\ a\ state\ over\ the\ set\ of\ possible\ actions\r\n\ according\ to\ softmax\ action\ selection\ strategy.\r\n\ @param\ n\ number\ of\ sucessor\ states\r\n\ @param\ A_s\ List\ of\ action\ options\ available\ to\ the\ agent\ at\ the\ given\ time\ in\ s.\r\n\ @param\ s_key\ key\ for\ given\ state\ s\r\n\ @return\ probability\ distribution\ for\ actions\ a\ in\ [0,1,...,n-1].\r\n
comment19.params=xs_key\ theta
comment19.target=void\ setTheta(java.lang.String,\ double[])
comment19.text=\ \r\n\ Set\ action\ preferences\ for\ a\ given\ state.\r\n\ @param\ xs_key\ observations\r\n\ @param\ theta\ parameters\ for\ action\ preferences\r\n
comment2.params=world
comment2.target=void\ addedToWorld(greenfoot.World)
comment20.params=xs_key
comment20.target=double[]\ getTheta(java.lang.String)
comment20.text=\ \r\n\ Get\ action\ preferences\ for\ a\ given\ state.\r\n\ @param\ xs_key\ observations\r\n\ @return\ parameters\ for\ action\ preferences\r\n
comment21.params=xs_key\ action
comment21.target=double\ getTheta_A(java.lang.String,\ int)
comment21.text=\ \r\n\ Get\ preferences\ for\ given\ state\ and\ action.\r\n\ @param\ xs_key\ observations\r\n\ @param\ a\ action\r\n\ @return\ parameter\ describing\ the\ action\ preference.\r\n
comment22.params=xs\ v
comment22.target=void\ setV(java.lang.String,\ double)
comment22.text=\r\n\ Sets\ a\ value\ for\ observed\ features\ xs.\r\n\ @param\ xs\ observed\ features\r\n\ @param\ v\ evaluation\ of\ the\ observation\r\n
comment23.params=xs
comment23.target=java.lang.Double\ getV(java.lang.String)
comment23.text=\r\n\ Gets\ value\ of\ observation\ xs.\r\n\ @param\ xs\ observed\ features\r\n\ @return\ stored\ evaluation\ of\ the\ given\ observation\r\n
comment3.params=
comment3.target=void\ act()
comment4.params=
comment4.target=java.lang.String\ getStateKey()
comment5.params=xs_key
comment5.target=double[]\ P_Policy(java.lang.String)
comment5.text=\r\n\ Stochastic\ policy\ of\ the\ agent.\ Assigns\ a\ probability\ distribution\ to\ a\ state\ over\ \r\n\ the\ set\ of\ possible\ actions.\r\n\ @param\ xs_key\ state\ key\r\n\ @return\ probability\ distribution\ for\ actions\ a\ in\ [0,1,...,n-1].\r\n
comment6.params=xs_key\ x\ y
comment6.target=double[]\ P_PolicyVisualization(java.lang.String,\ int,\ int)
comment7.params=A_s\ xs
comment7.target=double[]\ P_XSoftMax(java.util.List,\ java.lang.String)
comment7.text=\r\n\ Assigns\ a\ probability\ distribution\ to\ a\ feature\ vector\ over\ the\ set\ of\ possible\ actions\r\n\ according\ to\ softmax\ action\ selection\ strategy.\r\n\ @param\ n\ number\ of\ sucessor\ states\r\n\ @param\ A_s\ List\ of\ action\ options\ available\ to\ the\ agent\ at\ the\ given\ time\ in\ s.\r\n\ @param\ s_key\ key\ for\ given\ state\ s\r\n\ @return\ probability\ distribution\ for\ actions\ a\ in\ [0,1,...,n-1].\r\n
comment8.params=xs_key\ a\ reward\ xs_new_key\ episodeEnd
comment8.target=void\ update(java.lang.String,\ int,\ double,\ java.lang.String,\ boolean)
comment8.text=\r\n\ Actor-critic\ Update\r\n\ @param\ xs_key\ state\ key\ consisting\ of\ features\r\n\ @param\ a\ action\r\n\ @param\ reward\ Reward\r\n\ @param\ xs_key_new\ successor\ state\r\n\ @param\ end\ Has\ a\ terminal\ state\ or\ the\ step\ limit\ been\ reached?\r\n
comment9.params=xs\ a
comment9.target=double[]\ gradient_ln_pi(java.lang.String,\ int)
comment9.text=\r\n\ Calculates\ the\ policy\ gradient\ of\ a\ state\ consisting\ of\ a\ feature\ vector.\r\n\ @param\ xs\ the\ feature-state\ key\r\n\ @param\ x_sa\ feature\ vector\r\n\ @return\ gradient\r\n
numComments=24
