#BlueJ class context
comment0.target=QHamster_FV
comment0.text=\r\n\ A\ hamster\ agent\ with\ Q-learning\ using\ feature\ vectors.\ For\ comparison\ with\ stochastic\ policy-building\r\n\ actor-critic\ policy\ gradient.\r\n\r\n\ Supplementary\ material\ to\ the\ book\:\ \r\n\ "Reinforcement\ Learning\ From\ Scratch\:\ Understanding\ Current\ Approaches\ -\ with\ Examples\ in\ Java\ and\ Greenfoot"\ by\ Uwe\ Lorenz.\r\n\ https\://link.springer.com/book/10.1007/978-3-031-09030-1\r\n\ \r\n\ Ausgabe\ auf\ Deutsch\:\ https\://link.springer.com/book/9783662683101\r\n\ \r\n\ Licensing\ CC-BY-SA\ 4.0\ \r\n\ Attribution\ -\ Sharing\ under\ the\ same\ conditions\r\n\ \r\n\ www.facebook.com/ReinforcementLearningJava\r\n\ github.com/sn-code-inside/Reinforcement-Learning\r\n\r\n\ www.x-ai.eu\r\n\ \r\n\ @author\ Uwe\ Lorenz\r\n\ @version\ 1.2\ (14.11.2023)\r\n
comment1.params=
comment1.target=QHamster_FV()
comment10.params=
comment10.target=java.lang.String\ getStateKey()
comment11.params=s_key
comment11.target=java.lang.Integer\ getActionWithMaxQ(java.lang.String)
comment11.text=\r\n\ Gets\ the\ action\ with\ the\ largest\ Q\ value\ for\ a\ given\ state.\ If\ there\ are\ several\ Q_max\ actions\r\n\ with\ the\ same\ value,\ they\ are\ selected\ randomly.\ If\ there\ are\ no\ Q-values,\ then\ -1\ is\ returned.\r\n\ @param\ s_key\ state\ key\r\n\ @return\ Action\ with\ greatest\ Q-value\ stored\ for\ the\ state\ s.\ Null\ if\ state\ is\ unknown.\r\n
comment12.params=s_key
comment12.target=java.lang.Double\ maxQ(java.lang.String)
comment12.text=\r\n\ Gets\ the\ greatest\ Q-value\ stored\ for\ the\ state\ s.\r\n\ @param\ s_key\ state\ key\r\n\ @return\ greatest\ Q-value\ stored\ for\ the\ state\ s.\ Null\ if\ state\ is\ unknown.\r\n
comment13.params=s_key\ a\ v
comment13.target=void\ setQ(java.lang.String,\ int,\ double)
comment13.text=\r\n\ Sets\ a\ Q-value\ for\ the\ state-action\ pair\ (s,a).\r\n\ @param\ s\ state\ key\r\n\ @param\ v\ Q-value\ of\ the\ state-action\ pair\ (s,a)\ to\ be\ set.\r\n
comment14.params=s_key\ a
comment14.target=double\ getQ(java.lang.String,\ int)
comment14.text=\r\n\ Gets\ the\ Q-value\ for\ the\ state-action\ pair\ (s,a).\r\n\ @param\ s_key\ state\ key\r\n\ @param\ a\ action\r\n\ @return\ Q-value\r\n
comment15.params=s_key
comment15.target=java.lang.Double[]\ getQValues(java.lang.String)
comment15.text=\r\n\ Gets\ all\ Q-Values\ at\ given\ state\ s.\r\n\ @param\ s_key\ state\ key\r\n\ @return\ Array\ with\ the\ Q\ action\ values.\r\n
comment2.params=world
comment2.target=void\ addedToWorld(greenfoot.World)
comment3.params=xs_key
comment3.target=double[]\ P_Policy(java.lang.String)
comment3.text=\r\n\ Stochastic\ policy\ of\ the\ agent.\ Assigns\ a\ probability\ distribution\ to\ a\ state\ over\ \r\n\ the\ set\ of\ possible\ actions.\r\n\ @param\ xs_key\ state\ key\r\n\ @return\ probability\ distribution\ for\ actions\ a\ in\ [0,1,...,n-1].\r\n
comment4.params=xs_key\ x\ y
comment4.target=double[]\ P_PolicyVisualization(java.lang.String,\ int,\ int)
comment5.params=n\ A_s\ s_key
comment5.target=double[]\ P_EpsilonGreedy_Policy(int,\ java.util.List,\ java.lang.String)
comment5.text=\r\n\ Assigns\ a\ probability\ distribution\ to\ a\ state\ over\ the\ set\ of\ possible\ actions\r\n\ according\ to\ epsilon-greedy\ action\ selection\ strategy.\r\n\ @param\ n\ number\ of\ sucessor\ states\r\n\ @param\ A_s\ List\ of\ action\ options\ available\ to\ the\ agent\ at\ the\ given\ time\ in\ s.\r\n\ @param\ s_key\ key\ for\ given\ state\ s\r\n\ @return\ probability\ distribution\ for\ actions\ a\ in\ [0,1,...,n-1].\r\n
comment6.params=
comment6.target=void\ act()
comment6.text=\r\n\ This\ method\ is\ called\ once\ by\ Greenfoot\ as\ soon\ as\ the\ 'Act'\ button\ or\ repeatedly\ if\ the\ 'Run'\ button\ is\ clicked.\ \ \r\n
comment7.params=s_key\ a\ reward\ s_new_key\ end
comment7.target=void\ update(java.lang.String,\ int,\ double,\ java.lang.String,\ boolean)
comment7.text=\r\n\ Update\ of\ Q(s,a)\ \ ("Q-learning"\ approach)\r\n\ @param\ s_key\ state\ key\r\n\ @param\ a\ action\r\n\ @param\ reward\ Reward\r\n\ @param\ s_key_new\ Successor\ state\r\n\ @param\ end\ Has\ a\ terminal\ state\ or\ the\ step\ limit\ been\ reached?\r\n
comment8.params=
comment8.target=void\ startNewEpisode()
comment8.text=\r\n\ A\ new\ episode\ is\ started,\ i.e.\ logging,\ counter\ updates\ or\ reset\ and\ set\ agent\ to\ start\ position.\r\n\ Perform\ an\ evaluation\ period\ if\ necessary.\r\n
comment9.params=
comment9.target=java.lang.String\ getState()
numComments=16
